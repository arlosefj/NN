{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 双层网络，最基本网络结构，Cross-Entropy，ReLU，Init\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from load_data import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, validation_data, test_data = load_data_wrapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 30\n",
    "learning_rate = 0.1\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_node_input = 784\n",
    "n_node_hidden = 100\n",
    "n_node_output = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 权重与偏置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_init = 'xavier'\n",
    "b_init = 'zero'\n",
    "\n",
    "if W_init == 'normal':\n",
    "    W2 = np.random.randn(n_node_hidden, n_node_input)\n",
    "    W3 = np.random.randn(n_node_output, n_node_hidden)\n",
    "elif W_init == 'xavier':\n",
    "    W2 = np.random.randn(n_node_hidden, n_node_input) / np.sqrt(n_node_input)\n",
    "    W3 = np.random.randn(n_node_output, n_node_hidden) / np.sqrt(n_node_hidden)\n",
    "else : # 'he'\n",
    "    W2 = np.random.randn(n_node_hidden, n_node_input) / np.sqrt(n_node_input/2)\n",
    "    W3 = np.random.randn(n_node_output, n_node_hidden) / np.sqrt(n_node_hidden/2)\n",
    "\n",
    "if b_init == 'normal':\n",
    "    b2 = np.random.randn(n_node_hidden, 1)\n",
    "    b3 = np.random.randn(n_node_output, 1)\n",
    "else: # 'zero'\n",
    "    b2 = np.zeros([n_node_hidden, 1])\n",
    "    b3 = np.zeros([n_node_output, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "def relu(z):\n",
    "    \"\"\"The relu function.\"\"\"\n",
    "    return np.maximum(z, 0)\n",
    "\n",
    "def relu_prime(z):\n",
    "    \"\"\"Derivative of the relu function.\"\"\"\n",
    "    return np.where(z > 0, 1.0, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN_ERROR] Epoch 00:  3685 / 50000\n",
      "[ TEST_ERROR] Epoch 00:   397 / 10000\n",
      "[TRAIN_ERROR] Epoch 01:  1712 / 50000\n",
      "[ TEST_ERROR] Epoch 01:   292 / 10000\n",
      "[TRAIN_ERROR] Epoch 02:  1230 / 50000\n",
      "[ TEST_ERROR] Epoch 02:   255 / 10000\n",
      "[TRAIN_ERROR] Epoch 03:   986 / 50000\n",
      "[ TEST_ERROR] Epoch 03:   265 / 10000\n",
      "[TRAIN_ERROR] Epoch 04:   802 / 50000\n",
      "[ TEST_ERROR] Epoch 04:   237 / 10000\n",
      "[TRAIN_ERROR] Epoch 05:   650 / 50000\n",
      "[ TEST_ERROR] Epoch 05:   211 / 10000\n",
      "[TRAIN_ERROR] Epoch 06:   553 / 50000\n",
      "[ TEST_ERROR] Epoch 06:   226 / 10000\n",
      "[TRAIN_ERROR] Epoch 07:   454 / 50000\n",
      "[ TEST_ERROR] Epoch 07:   224 / 10000\n",
      "[TRAIN_ERROR] Epoch 08:   378 / 50000\n",
      "[ TEST_ERROR] Epoch 08:   223 / 10000\n",
      "[TRAIN_ERROR] Epoch 09:   363 / 50000\n",
      "[ TEST_ERROR] Epoch 09:   226 / 10000\n",
      "[TRAIN_ERROR] Epoch 10:   271 / 50000\n",
      "[ TEST_ERROR] Epoch 10:   206 / 10000\n",
      "[TRAIN_ERROR] Epoch 11:   226 / 50000\n",
      "[ TEST_ERROR] Epoch 11:   218 / 10000\n",
      "[TRAIN_ERROR] Epoch 12:   207 / 50000\n",
      "[ TEST_ERROR] Epoch 12:   218 / 10000\n",
      "[TRAIN_ERROR] Epoch 13:   185 / 50000\n",
      "[ TEST_ERROR] Epoch 13:   220 / 10000\n",
      "[TRAIN_ERROR] Epoch 14:   129 / 50000\n",
      "[ TEST_ERROR] Epoch 14:   202 / 10000\n",
      "[TRAIN_ERROR] Epoch 15:    95 / 50000\n",
      "[ TEST_ERROR] Epoch 15:   215 / 10000\n",
      "[TRAIN_ERROR] Epoch 16:    67 / 50000\n",
      "[ TEST_ERROR] Epoch 16:   213 / 10000\n",
      "[TRAIN_ERROR] Epoch 17:    38 / 50000\n",
      "[ TEST_ERROR] Epoch 17:   204 / 10000\n",
      "[TRAIN_ERROR] Epoch 18:    32 / 50000\n",
      "[ TEST_ERROR] Epoch 18:   208 / 10000\n",
      "[TRAIN_ERROR] Epoch 19:    21 / 50000\n",
      "[ TEST_ERROR] Epoch 19:   213 / 10000\n",
      "[TRAIN_ERROR] Epoch 20:    11 / 50000\n",
      "[ TEST_ERROR] Epoch 20:   198 / 10000\n",
      "[TRAIN_ERROR] Epoch 21:     2 / 50000\n",
      "[ TEST_ERROR] Epoch 21:   190 / 10000\n",
      "[TRAIN_ERROR] Epoch 22:     2 / 50000\n",
      "[ TEST_ERROR] Epoch 22:   191 / 10000\n",
      "[TRAIN_ERROR] Epoch 23:     1 / 50000\n",
      "[ TEST_ERROR] Epoch 23:   196 / 10000\n",
      "[TRAIN_ERROR] Epoch 24:     1 / 50000\n",
      "[ TEST_ERROR] Epoch 24:   178 / 10000\n",
      "[TRAIN_ERROR] Epoch 25:     0 / 50000\n",
      "[ TEST_ERROR] Epoch 25:   192 / 10000\n",
      "[TRAIN_ERROR] Epoch 26:     0 / 50000\n",
      "[ TEST_ERROR] Epoch 26:   187 / 10000\n",
      "[TRAIN_ERROR] Epoch 27:     0 / 50000\n",
      "[ TEST_ERROR] Epoch 27:   185 / 10000\n",
      "[TRAIN_ERROR] Epoch 28:     0 / 50000\n",
      "[ TEST_ERROR] Epoch 28:   184 / 10000\n",
      "[TRAIN_ERROR] Epoch 29:     0 / 50000\n",
      "[ TEST_ERROR] Epoch 29:   184 / 10000\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "### Training\n",
    "test_errors = []\n",
    "training_errors = []\n",
    "n = len(training_data)\n",
    "\n",
    "\n",
    "for j in range(n_epoch):\n",
    "\n",
    "    ## Stochastic Gradient Descent\n",
    "    np.random.shuffle(training_data)\n",
    "\n",
    "    # for each batch\n",
    "    sum_of_training_error = 0\n",
    "    for k in range(0, n, batch_size):\n",
    "        batch = training_data[k:k+batch_size]\n",
    "\n",
    "        # average gradient for samples in a batch\n",
    "        sum_gradient_b3 = 0\n",
    "        sum_gradient_b2 = 0\n",
    "        sum_gradient_W3 = 0\n",
    "        sum_gradient_W2 = 0\n",
    "\n",
    "        # for each sample\n",
    "        for x, y in batch:\n",
    "            ## Feed forward\n",
    "\n",
    "            a1 = x\n",
    "            z2 = np.dot(W2, a1) + b2\n",
    "            a2 = relu(z2)\n",
    "            z3 = np.dot(W3, a2) + b3\n",
    "            a3 = sigmoid(z3)\n",
    "\n",
    "            ## Backpropagation\n",
    "\n",
    "            # Step 1: Error at the output layer [Cross-Entropy Cost]\n",
    "            delta_3 = (a3-y)\n",
    "            # Step 2: Error relationship between two adjacent layers\n",
    "            delta_2 =  relu_prime(z2)*np.dot(W3.transpose(), delta_3)\n",
    "            # Step 3: Gradient of C in terms of bias\n",
    "            gradient_b3 = delta_3\n",
    "            gradient_b2 = delta_2\n",
    "            # Step 4: Gradient of C in terms of weight\n",
    "            gradient_W3 = np.dot(delta_3, a2.transpose())\n",
    "            gradient_W2 = np.dot(delta_2, a1.transpose())\n",
    "\n",
    "            # update gradients\n",
    "            sum_gradient_b3 += gradient_b3\n",
    "            sum_gradient_b2 += gradient_b2\n",
    "            sum_gradient_W3 += gradient_W3\n",
    "            sum_gradient_W2 += gradient_W2\n",
    "\n",
    "            ## Training Error\n",
    "            sum_of_training_error += int(np.argmax(a3) != np.argmax(y))\n",
    "\n",
    "        # Update Biases\n",
    "        b3 -= learning_rate * sum_gradient_b3 / batch_size\n",
    "        b2 -= learning_rate * sum_gradient_b2 / batch_size\n",
    "\n",
    "        # Update Weights\n",
    "        W3 -= learning_rate * sum_gradient_W3 / batch_size\n",
    "        W2 -= learning_rate * sum_gradient_W2 / batch_size\n",
    "\n",
    "    # Report Training Error\n",
    "    print(\"[TRAIN_ERROR] Epoch %02d: %5d / %05d\" % (j, sum_of_training_error, n))\n",
    "    training_errors.append(np.float(sum_of_training_error) / n)\n",
    "\n",
    "    ### Test\n",
    "    n_test = len(test_data)\n",
    "    sum_of_test_error = 0\n",
    "    for x, y in test_data:\n",
    "        ## Feed forward\n",
    "\n",
    "        a1 = x\n",
    "        z2 = np.dot(W2, a1) + b2\n",
    "        a2 = relu(z2)\n",
    "        z3 = np.dot(W3, a2) + b3\n",
    "        a3 = sigmoid(z3)\n",
    "\n",
    "        ## Test Error\n",
    "        # in test data, label info is a number not one-hot vector as in training data\n",
    "        sum_of_test_error += int(np.argmax(a3) != y)\n",
    "\n",
    "    # Report Test Error\n",
    "    print(\"[ TEST_ERROR] Epoch %02d: %5d / %05d\" % (j, sum_of_test_error, n_test))\n",
    "\n",
    "    test_errors.append(np.float(sum_of_test_error)/n_test)\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
